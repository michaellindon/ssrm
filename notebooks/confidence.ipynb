{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Sequences\n",
    "### Only implemented for binomial data (currently)\n",
    "In addition to strict hypothesis testing in the previous notebook, it is useful for the analysis to perform some complementary *estimation*. For instance, suppose that our null hypothesis in the previous notebook was rejected. A naturally question to ask is \"Well, what is the true probability?\". One way to assess this is through *confidence sequences*. A collection of intervals with desired coverage of at least $1-\\alpha$ is called a conservative confidence sequence if the intersection of these intervals covers the true parameter value with probability at least $1-\\alpha$. This allows you to get confidence statements in real time using all of the data up until the current time. Here is an example to show what this looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multinomial\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed of our random number generator for reproducibility. Don't worry about this\n",
    "np.random.seed(1)\n",
    "\n",
    "# Our estimated binomial probabilities\n",
    "p_0 = [0.5, 0.5]\n",
    "assert p_0[0] == 1 - p_0[1]\n",
    "\n",
    "\n",
    "# The actual binomial probabilities\n",
    "p = [0.7, 0.3]\n",
    "assert p[0] == 1 - p[1]\n",
    "\n",
    "# Specify number of visitors\n",
    "n = 10000\n",
    "\n",
    "# Generate allocations\n",
    "data = multinomial.rvs(10, p, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssrm_test import ssrm_test, confidence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.array(data)\n",
    "null_probabilities = np.array(p_0)\n",
    "dirichlet_probabilities = np.array(null_probabilities)\n",
    "dirichlet_concentration = 1\n",
    "posteriors = ssrm_test.sequential_posteriors(\n",
    "    data, null_probabilities, dirichlet_probabilities, dirichlet_concentration\n",
    ")\n",
    "\n",
    "np.random.seed(1)\n",
    "confidence_intervals = confidence.confidence_sequence(posteriors, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    [ci[0] for ci in confidence_intervals],\n",
    "    color=\"steelblue\",\n",
    "    label=\"Lower Confidence Bound\",\n",
    ")\n",
    "plt.plot(\n",
    "    [ci[1] for ci in confidence_intervals],\n",
    "    color=\"steelblue\",\n",
    "    label=\"Upper Confidence Bound\",\n",
    ")\n",
    "plt.hlines(\n",
    "    y=p[0],\n",
    "    xmin=0,\n",
    "    xmax=len(confidence_intervals),\n",
    "    linestyle=\"dashed\",\n",
    "    color=\"red\",\n",
    "    label=\"True Value\",\n",
    ")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to play around with these a little. Note that the coverage probability of the confidence sequence is maintained no matter what estimate $p_0$ is provided, though the narrower the confidence sequence the better the estimate. If in doubt, just use $p_0 = [0.5, 0.5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
